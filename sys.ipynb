import pandas as pd
import numpy
import nltk
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize,sent_tokenize
from nltk.stem import WordNetLemmatizer
from nltk import tokenize
import contractions
import re
import string



df = pd.read_csv('Restaurant_Reviews.tsv',sep='\t')
df.head()
punctuations=list(string.punctuation)
df.Review=df.Review.apply(lambda x : " ".join(x for x in x.split() if x not in punctuations))
nltk.download('stopwords')
stopword_list=stopwords.words('english')
stopword_list.remove('no')
stopword_list.remove('not')


def remove_sp(text):
  pattern=r'[^A-Za-z0-9\s]'
  text=re.sub(pattern,'',text)
  return text

def con(text):
  expand=contractions.fix(text)
  return expand

df.Review=df.Review.apply(con)
df['Review'][0]

